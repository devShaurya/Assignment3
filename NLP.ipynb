{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devShaurya/Assignment3/blob/master/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdGJLEPFKbVt",
        "colab_type": "code",
        "outputId": "9a15e3ef-c9b1-4955-f9c3-4045771f3768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsPVVz_QKn63",
        "colab_type": "code",
        "outputId": "303dd40b-50da-4b36-f1e1-e883c2e8b054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D6H6zA8Kpbk",
        "colab_type": "code",
        "outputId": "ffdef613-e66f-45d3-ddec-287e19aa466d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m'My Drive'\u001b[0m/  \u001b[01;34m'Shared drives'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nxQEbYuKtGj",
        "colab_type": "code",
        "outputId": "3d572bea-696b-45a7-8c29-763c9ff3ad1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd My Drive"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcqYQyLvK74m",
        "colab_type": "code",
        "outputId": "38a93e22-ee70-4468-e128-74347b87359a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd NLP\\ Embeddings"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/NLP Embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0iupD94K_NN",
        "colab_type": "code",
        "outputId": "7e5a2452-11d1-43bf-d36c-e4a9f11ca4fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT_Fine_Tuning_Sentence_Classification.ipynb        lstm.hdf5\n",
            "BERT_Fine_Tuning_Sentence_Classification_where.ipynb  Tatti-Copy1.ipynb\n",
            "bert_test.npy                                         Tatti-Copy3.ipynb\n",
            "bert_train.npy                                        test.txt\n",
            "\u001b[0m\u001b[01;34mdata\u001b[0m/                                                 train.txt\n",
            "embed_copy.npy                                        ytest.npy\n",
            "embed_test_copy.npy                                   ytrain.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbKXN1Ilb9qh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a72203b6-ee60-4121-e593-97cb03cbfc02"
      },
      "source": [
        "!pip install keras-self-attention"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.6/dist-packages (0.42.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.17.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.3.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irQNxiaUloek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Preprocessing:\n",
        "    def __init__(self,test,train):\n",
        "        self.testFile=test\n",
        "        self.trainFile=train\n",
        "    def htmlProcess(self,sentence):\n",
        "        html=-1\n",
        "        dot=-1\n",
        "        final=[]\n",
        "        i=0\n",
        "        while(i<len(sentence)):\n",
        "            if(sentence[i].lower().find(\"http\")!=-1):\n",
        "                html=i\n",
        "            if((re.search(\"co\",sentence[i].lower()) or re.search(\"tco\",sentence[i].lower())) and html!=-1):\n",
        "                dot=i\n",
        "            if(html!=-1 and dot!=-1 and dot<=len(sentence)-2):\n",
        "                del sentence[html:dot+2]\n",
        "                i=html\n",
        "                html=-1\n",
        "                dot=-1\n",
        "            i+=1\n",
        "        return sentence\n",
        "    def process_file(self):\n",
        "        for u,i in enumerate([self.testFile,self.trainFile]):\n",
        "            with open(i) as file:\n",
        "                data = file.read()\n",
        "            lines=data.split('\\n')\n",
        "            sentInput=[]\n",
        "            sentOutput=[]\n",
        "            dic={'ENG':0,'HIN':1,'O':2}\n",
        "            mape={}\n",
        "            i=0\n",
        "            while(i<len(lines)):\n",
        "                temp=lines[i].split()\n",
        "                if(len(temp)>=2):\n",
        "                    if(temp[0]=='meta' and len(temp)==3):\n",
        "                        mape[temp[1]]=len(sentInput)\n",
        "                        if(len(sentInput)!=0):\n",
        "                            sentInput[-1]=self.htmlProcess(sentInput[-1])\n",
        "                        sentInput.append([])\n",
        "                        sentOutput.append(temp[2])\n",
        "                    else:\n",
        "                        if(temp[0].find(\"@\")==len(temp[0])-1 or temp[0].find(\"#\")==len(temp[0])-1):\n",
        "                            i+=1\n",
        "                        else:\n",
        "                            data_clean=re.sub(\"[^a-zA-Z]+\", \"\",temp[0])\n",
        "                            if(len(data_clean)!=0):\n",
        "                                sentInput[-1].append(data_clean)\n",
        "                i+=1\n",
        "            sentInput[-1]=self.htmlProcess(sentInput[-1])\n",
        "            if(u==0):\n",
        "                self.testInput,self.testOutput,self.test_map=sentInput,sentOutput,mape\n",
        "            else:\n",
        "                self.trainInput,self.trainOutput,self.train_map=sentInput,sentOutput,mape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aP8OXh4nO2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obj=Preprocessing(\"test.txt\",\"train.txt\")\n",
        "obj.process_file()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxHKt3xF3nr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_raw=obj.trainInput\n",
        "X_test_raw=obj.testInput"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXqmqvImjeH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "201CEvfiq9gM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data import Sentence\n",
        "\n",
        "X_testFlair = [Sentence(\" \".join(tweet)) for tweet in X_test_raw]\n",
        "X_trainFlair=[Sentence(\" \".join(tweet)) for tweet in X_train_raw]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNINaPsZjcuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.embeddings import FlairEmbeddings, BertEmbeddings\n",
        "# init multilingual BERT\n",
        "bert_embedding = BertEmbeddings('bert-base-multilingual-cased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu67Yghy4pm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_trainB = []\n",
        "for sent in X_trainFlair:\n",
        "  sentEmb = np.array(bert_embedding.embed(sent)[0])\n",
        "  emb = []\n",
        "  for token in sentEmb:\n",
        "    emb.append(np.array(token.embedding.cpu()))\n",
        "  X_trainB.append(np.array(emb))\n",
        "X_testB = []\n",
        "for sent in X_testFlair:\n",
        "  sentEmb = np.array(bert_embedding.embed(sent)[0])\n",
        "  emb = []\n",
        "  for token in sentEmb:\n",
        "    emb.append(np.array(token.embedding.cpu()))\n",
        "  X_testB.append(np.array(emb))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVxU_G0R5ChF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"embed_copy\",X_trainB)\n",
        "np.save(\"embed_test_copy\",X_testB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RgFHpbpcV0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM, Bidirectional,Flatten,GRU\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import backend as K\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "npEmb_train=np.load(\"bert_train.npy\",allow_pickle=1)\n",
        "npEmb_test=np.load(\"bert_test.npy\",allow_pickle=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFpMlIADcyIE",
        "colab_type": "code",
        "outputId": "e4b3b8ae-34fe-4884-92dd-b14edd4b5c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "print(npEmb_train[0].shape)  \n",
        "print(npEmb_test.shape)  \n",
        "X_train = npEmb_train\n",
        "X_test = npEmb_test\n",
        "embList = []\n",
        "for i in X_train:\n",
        "  embList.append(torch.tensor(i[:31]))\n",
        "X_train = pad_sequence(embList, batch_first=True)\n",
        "#X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=500)\n",
        "embList = []\n",
        "for i in X_test:\n",
        "  embList.append(torch.tensor(i[:31]))\n",
        "X_test = pad_sequence(embList, batch_first=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18, 3072)\n",
            "(1869,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHtoZ9XqdWnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l=[]\n",
        "m=[]\n",
        "npEmbTrain=np.load(\"embed_copy.npy\",allow_pickle=1)\n",
        "npEmbTest=np.load(\"embed_test_copy.npy\",allow_pickle=1)\n",
        "\n",
        "embeddings_polarity=npEmbTrain.tolist()\n",
        "for i in range(len(embeddings_polarity)):\n",
        "    l.append(embeddings_polarity[i][0])\n",
        "    if embeddings_polarity[i][1].lower()=='positive':\n",
        "        m.append(1)\n",
        "    elif embeddings_polarity[i][1].lower()=='negative':\n",
        "        m.append(2)\n",
        "    else:\n",
        "        m.append(0)\n",
        "l1=[]\n",
        "m1=[]\n",
        "embeddings_test=npEmbTest.tolist()\n",
        "for i in range(len(embeddings_test)):\n",
        "    l1.append(embeddings_test[i][0])\n",
        "    if embeddings_test[i][1].lower()=='positive':\n",
        "        m1.append(1)\n",
        "    elif embeddings_test[i][1].lower()=='negative':\n",
        "        m1.append(2)\n",
        "    else:\n",
        "        m1.append(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vMUNqfIdg9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train=np.load(\"Ytrain.npy\")\n",
        "Y_test=np.load(\"ytest.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2VyLUnddisi",
        "colab_type": "code",
        "outputId": "9619f5a2-6d88-4b56-8925-b0cd04abe9b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def LSTM_model():\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(128,input_shape=(35,3072),return_sequences=1)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(SeqSelfAttention(attention_width=15,attention_activation='sigmoid'))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.add(GRU(20))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc',f1_m,precision_m, recall_m])\n",
        "    #print(model.summary())\n",
        "    filepath=\"lstm.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "    callbacks_list = [checkpoint]\n",
        "    model.fit(X_train.numpy(), Y_train, epochs=10, batch_size=256,callbacks=callbacks_list)\n",
        "    return model\n",
        "model=LSTM_model()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "15131/15131 [==============================] - 17s 1ms/step - loss: 1.0087 - acc: 0.4634 - f1_m: 0.1665 - precision_m: 0.5121 - recall_m: 0.1058\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.00873, saving model to lstm.hdf5\n",
            "Epoch 2/10\n",
            "15131/15131 [==============================] - 11s 753us/step - loss: 0.9085 - acc: 0.5447 - f1_m: 0.3757 - precision_m: 0.6627 - recall_m: 0.2671\n",
            "\n",
            "Epoch 00002: loss improved from 1.00873 to 0.90845, saving model to lstm.hdf5\n",
            "Epoch 3/10\n",
            "15131/15131 [==============================] - 11s 743us/step - loss: 0.8696 - acc: 0.5790 - f1_m: 0.4669 - precision_m: 0.6512 - recall_m: 0.3665\n",
            "\n",
            "Epoch 00003: loss improved from 0.90845 to 0.86962, saving model to lstm.hdf5\n",
            "Epoch 4/10\n",
            "15131/15131 [==============================] - 11s 742us/step - loss: 0.8299 - acc: 0.6062 - f1_m: 0.5379 - precision_m: 0.6568 - recall_m: 0.4564\n",
            "\n",
            "Epoch 00004: loss improved from 0.86962 to 0.82990, saving model to lstm.hdf5\n",
            "Epoch 5/10\n",
            "15131/15131 [==============================] - 11s 746us/step - loss: 0.7906 - acc: 0.6394 - f1_m: 0.6040 - precision_m: 0.6743 - recall_m: 0.5475\n",
            "\n",
            "Epoch 00005: loss improved from 0.82990 to 0.79059, saving model to lstm.hdf5\n",
            "Epoch 6/10\n",
            "15131/15131 [==============================] - 11s 735us/step - loss: 0.7420 - acc: 0.6705 - f1_m: 0.6488 - precision_m: 0.6951 - recall_m: 0.6085\n",
            "\n",
            "Epoch 00006: loss improved from 0.79059 to 0.74200, saving model to lstm.hdf5\n",
            "Epoch 7/10\n",
            "15131/15131 [==============================] - 11s 734us/step - loss: 0.6964 - acc: 0.7017 - f1_m: 0.6869 - precision_m: 0.7193 - recall_m: 0.6575\n",
            "\n",
            "Epoch 00007: loss improved from 0.74200 to 0.69639, saving model to lstm.hdf5\n",
            "Epoch 8/10\n",
            "15131/15131 [==============================] - 11s 738us/step - loss: 0.6411 - acc: 0.7333 - f1_m: 0.7247 - precision_m: 0.7483 - recall_m: 0.7027\n",
            "\n",
            "Epoch 00008: loss improved from 0.69639 to 0.64107, saving model to lstm.hdf5\n",
            "Epoch 9/10\n",
            "15131/15131 [==============================] - 11s 743us/step - loss: 0.5947 - acc: 0.7585 - f1_m: 0.7540 - precision_m: 0.7707 - recall_m: 0.7381\n",
            "\n",
            "Epoch 00009: loss improved from 0.64107 to 0.59470, saving model to lstm.hdf5\n",
            "Epoch 10/10\n",
            "15131/15131 [==============================] - 11s 735us/step - loss: 0.5525 - acc: 0.7800 - f1_m: 0.7762 - precision_m: 0.7903 - recall_m: 0.7627\n",
            "\n",
            "Epoch 00010: loss improved from 0.59470 to 0.55253, saving model to lstm.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x37hlYxkdk0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3bf809d-f8bf-4ce4-fe96-6b6c6a25599d"
      },
      "source": [
        "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, Y_test, verbose=0)\n",
        "accuracy, f1_score, precision,recall"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5141787053493971, 0.5078455995212205, 0.5159723916240017, 0.50026752293078)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOYsbRYFheqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "ade040cf-7950-408b-8579-44681b9d337d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_1 (Bidirection (None, 31, 256)           3277824   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 31, 256)           0         \n",
            "_________________________________________________________________\n",
            "seq_self_attention_1 (SeqSel (None, 31, 256)           16449     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 31, 3)             771       \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 20)                1440      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 3,296,547\n",
            "Trainable params: 3,296,547\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeC_yIEUubQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=model.predict_classes(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY2DkHpGpKnh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e418f87a-8e68-4156-8342-9ff17d57576d"
      },
      "source": [
        "y_dct = {'negative':0, \"neutral\":1,\"positive\":2}\n",
        "y_test_int = []\n",
        "for i in range(len(Y_test)):\n",
        "      y_test_int.append(list(Y_test[i]).index(1))\n",
        "from sklearn.metrics import classification_report as clf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "target_names=['negative','neutral','positive']\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_matrix(y_test_int, y_pred), columns=target_names, index=target_names)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "print(df_cm)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy: \",accuracy_score(y_test_int, y_pred))\n",
        "print(\"\\n\",\"Report:\")\n",
        "print(clf(y_test_int, y_pred, target_names=target_names))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted  negative  neutral  positive\n",
            "Actual                                \n",
            "negative        402      110        21\n",
            "neutral         322      334        98\n",
            "positive        133      224       225\n",
            "\n",
            "\n",
            "Accuracy:  0.5141787051899411\n",
            "\n",
            " Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.47      0.75      0.58       533\n",
            "     neutral       0.50      0.44      0.47       754\n",
            "    positive       0.65      0.39      0.49       582\n",
            "\n",
            "    accuracy                           0.51      1869\n",
            "   macro avg       0.54      0.53      0.51      1869\n",
            "weighted avg       0.54      0.51      0.51      1869\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGI3NzVpuUBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}