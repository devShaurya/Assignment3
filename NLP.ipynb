{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devShaurya/Assignment3/blob/master/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdGJLEPFKbVt",
        "colab_type": "code",
        "outputId": "9a15e3ef-c9b1-4955-f9c3-4045771f3768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsPVVz_QKn63",
        "colab_type": "code",
        "outputId": "303dd40b-50da-4b36-f1e1-e883c2e8b054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D6H6zA8Kpbk",
        "colab_type": "code",
        "outputId": "ffdef613-e66f-45d3-ddec-287e19aa466d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m'My Drive'\u001b[0m/  \u001b[01;34m'Shared drives'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nxQEbYuKtGj",
        "colab_type": "code",
        "outputId": "3d572bea-696b-45a7-8c29-763c9ff3ad1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd My Drive"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcqYQyLvK74m",
        "colab_type": "code",
        "outputId": "38a93e22-ee70-4468-e128-74347b87359a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd NLP\\ Embeddings"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/NLP Embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0iupD94K_NN",
        "colab_type": "code",
        "outputId": "7e5a2452-11d1-43bf-d36c-e4a9f11ca4fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT_Fine_Tuning_Sentence_Classification.ipynb        lstm.hdf5\n",
            "BERT_Fine_Tuning_Sentence_Classification_where.ipynb  Tatti-Copy1.ipynb\n",
            "bert_test.npy                                         Tatti-Copy3.ipynb\n",
            "bert_train.npy                                        test.txt\n",
            "\u001b[0m\u001b[01;34mdata\u001b[0m/                                                 train.txt\n",
            "embed_copy.npy                                        ytest.npy\n",
            "embed_test_copy.npy                                   ytrain.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbKXN1Ilb9qh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a72203b6-ee60-4121-e593-97cb03cbfc02"
      },
      "source": [
        "!pip install keras-self-attention"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.6/dist-packages (0.42.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.17.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.3.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irQNxiaUloek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Preprocessing:\n",
        "    def __init__(self,test,train):\n",
        "        self.testFile=test\n",
        "        self.trainFile=train\n",
        "    def htmlProcess(self,sentence):\n",
        "        html=-1\n",
        "        dot=-1\n",
        "        final=[]\n",
        "        i=0\n",
        "        while(i<len(sentence)):\n",
        "            if(sentence[i].lower().find(\"http\")!=-1):\n",
        "                html=i\n",
        "            if((re.search(\"co\",sentence[i].lower()) or re.search(\"tco\",sentence[i].lower())) and html!=-1):\n",
        "                dot=i\n",
        "            if(html!=-1 and dot!=-1 and dot<=len(sentence)-2):\n",
        "                del sentence[html:dot+2]\n",
        "                i=html\n",
        "                html=-1\n",
        "                dot=-1\n",
        "            i+=1\n",
        "        return sentence\n",
        "    def process_file(self):\n",
        "        for u,i in enumerate([self.testFile,self.trainFile]):\n",
        "            with open(i) as file:\n",
        "                data = file.read()\n",
        "            lines=data.split('\\n')\n",
        "            sentInput=[]\n",
        "            sentOutput=[]\n",
        "            dic={'ENG':0,'HIN':1,'O':2}\n",
        "            mape={}\n",
        "            i=0\n",
        "            while(i<len(lines)):\n",
        "                temp=lines[i].split()\n",
        "                if(len(temp)>=2):\n",
        "                    if(temp[0]=='meta' and len(temp)==3):\n",
        "                        mape[temp[1]]=len(sentInput)\n",
        "                        if(len(sentInput)!=0):\n",
        "                            sentInput[-1]=self.htmlProcess(sentInput[-1])\n",
        "                        sentInput.append([])\n",
        "                        sentOutput.append(temp[2])\n",
        "                    else:\n",
        "                        if(temp[0].find(\"@\")==len(temp[0])-1 or temp[0].find(\"#\")==len(temp[0])-1):\n",
        "                            i+=1\n",
        "                        else:\n",
        "                            data_clean=re.sub(\"[^a-zA-Z]+\", \"\",temp[0])\n",
        "                            if(len(data_clean)!=0):\n",
        "                                sentInput[-1].append(data_clean)\n",
        "                i+=1\n",
        "            sentInput[-1]=self.htmlProcess(sentInput[-1])\n",
        "            if(u==0):\n",
        "                self.testInput,self.testOutput,self.test_map=sentInput,sentOutput,mape\n",
        "            else:\n",
        "                self.trainInput,self.trainOutput,self.train_map=sentInput,sentOutput,mape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aP8OXh4nO2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obj=Preprocessing(\"test.txt\",\"train.txt\")\n",
        "obj.process_file()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXqmqvImjeH0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46584002-7ab2-4cbc-f81e-9abc0ef90e5c"
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/22/8fc8e5978ec05b710216735ca47415700e83f304dec7e4281d61cefb6831/flair-0.4.4-py3-none-any.whl (193kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 17.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 2.8MB/s \n",
            "\u001b[?25hCollecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
            "Collecting transformers>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.1.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.5)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 52.8MB/s \n",
            "\u001b[?25hCollecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 55.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n",
            "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Collecting bpemb>=0.2.9\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Collecting tiny-tokenizer[all]\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/ee/08078f68165a7465f028f3505e6a749b50f6f5c229bd272a863ab07acdc2/tiny_tokenizer-3.0.1.tar.gz\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/89/62912e01f3cede11edcc0abf81298e3439d9c06c8dce644369380ed13f6d/Deprecated-1.2.7-py2.py3-none-any.whl\n",
            "Collecting ipython==7.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2c/c7d44277b599df35af734d8f4142d501192fdb7aef5d04daf882d7eccfbc/ipython-7.6.1-py3-none-any.whl (774kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 58.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from flair) (0.4.2+cu100)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 62.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from flair) (3.9.0)\n",
            "Requirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from flair) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.3.1+cu100)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 46.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (2.21.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (1.17.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (1.10.14)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (41.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.12.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (7.2.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.9.0)\n",
            "Collecting natto-py\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/a0/eaac1ed66c02823a2423a21de863da53a5268ce77582d91d1edb45a403dc/natto-py-0.9.0.tar.gz\n",
            "Collecting kytea\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/bc/702d01a96d5d094bd9f3c2eb1d12153daf8edf7bf5d78b9a2dae1202df07/kytea-0.1.4-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 23.0MB/s \n",
            "\u001b[?25hCollecting SudachiPy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/09/7c55ab89d7bcdd8075929add8b096c4b5347d661d78e7d4884214f672513/SudachiPy-0.4.0-py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (2.1.3)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.15.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.4.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.7.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.1.0)\n",
            "Collecting prompt-toolkit<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/61/2dfea88583d5454e3a64f9308a686071d58d59a55db638268a6413e1eb6d/prompt_toolkit-2.0.10-py3-none-any.whl (340kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 60.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->flair) (4.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.0.0->flair) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.0.0->flair) (0.14.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.0.0->flair) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.0.0->flair) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.0.0->flair) (2019.9.11)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.14 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (1.13.14)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from natto-py->tiny-tokenizer[all]->flair) (1.13.2)\n",
            "Requirement already satisfied: sortedcontainers~=2.1.0 in /usr/local/lib/python3.6/dist-packages (from SudachiPy->tiny-tokenizer[all]->flair) (2.1.0)\n",
            "Collecting dartsclone~=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/4d/45acbe9d0795d8ceef0fee1f9ac2dcbf27dca3a0578a023fcdc3fef6fd89/dartsclone-0.6.tar.gz\n",
            "Requirement already satisfied: parso>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython==7.6.1->flair) (0.5.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython==7.6.1->flair) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.6.1->flair) (0.1.7)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision->flair) (0.46)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->transformers>=2.0.0->flair) (0.15.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->natto-py->tiny-tokenizer[all]->flair) (2.19)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from dartsclone~=0.6.0->SudachiPy->tiny-tokenizer[all]->flair) (0.29.14)\n",
            "Building wheels for collected packages: segtok, mpld3, tiny-tokenizer, sqlitedict, langdetect, sacremoses, natto-py, dartsclone\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23258 sha256=150064016c69dd6d422f2d892b8c1c0eba3b453294ad8e01258819cfae9bbd94\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=0c0d25d140779aab6b61c4463d575a30bda68f4475f9f02c02caa6178ae6b69f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for tiny-tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tiny-tokenizer: filename=tiny_tokenizer-3.0.1-cp36-none-any.whl size=9444 sha256=d57c8f605c2beedd94cae8b1a8abdf11ca74ce8f9a57f9d2aeb66745ee38370e\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/04/72/d04956c4b03e3b03e5e095c06cbabc9bfb6f1bec02288eacdb\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=10b106c7580e548b1772dd3f688b8695c60764d5273124a8921315d3e426b1da\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.7-cp36-none-any.whl size=993460 sha256=abfdb332dc7b329b6e0bbee39a829b6634ad4d2f8f707e29f464d013a097241f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=59f3525744e12f6784242070dcbcf833ded38421ebe87b1950f80b8d54eaffc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "  Building wheel for natto-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for natto-py: filename=natto_py-0.9.0-cp36-none-any.whl size=45075 sha256=a8923b2baaa9d52fd97e72a0b8e46602485d9b8ebe159520a8b818e8d6dfc877\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/98/3a/ebfb1636e18698b3f47d8caa3f90fc3a91f1ea58430616018f\n",
            "  Building wheel for dartsclone (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dartsclone: filename=dartsclone-0.6-cp36-cp36m-linux_x86_64.whl size=413251 sha256=eb8cb1350f4cff33271c2aa36e6a408cbd52429cf550f323125df39fe72d9bcf\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/cd/70/fe43307bf7398243155108f4f5a258ef336923d65ec4af93cd\n",
            "Successfully built segtok mpld3 tiny-tokenizer sqlitedict langdetect sacremoses natto-py dartsclone\n",
            "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.6.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: regex, segtok, sacremoses, sentencepiece, transformers, mpld3, bpemb, natto-py, kytea, dartsclone, SudachiPy, tiny-tokenizer, sqlitedict, deprecated, prompt-toolkit, ipython, langdetect, flair\n",
            "  Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "Successfully installed SudachiPy-0.4.0 bpemb-0.3.0 dartsclone-0.6 deprecated-1.2.7 flair-0.4.4 ipython-7.6.1 kytea-0.1.4 langdetect-1.0.7 mpld3-0.3 natto-py-0.9.0 prompt-toolkit-2.0.10 regex-2019.11.1 sacremoses-0.0.35 segtok-1.5.7 sentencepiece-0.1.83 sqlitedict-1.6.0 tiny-tokenizer-3.0.1 transformers-2.1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "201CEvfiq9gM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data import Sentence\n",
        "\n",
        "X_test_flair = [Sentence(tweet) for tweet in X_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNINaPsZjcuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.embeddings import FlairEmbeddings, BertEmbeddings\n",
        "\n",
        "# init Flair embeddings\n",
        "flair_forward_embedding = FlairEmbeddings('multi-forward')\n",
        "flair_backward_embedding = FlairEmbeddings('multi-backward')\n",
        "\n",
        "# init multilingual BERT\n",
        "bert_embedding = BertEmbeddings('bert-base-multilingual-cased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RgFHpbpcV0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM, Bidirectional,Flatten,GRU\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import backend as K\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "np_emb_train=np.load(\"bert_train.npy\",allow_pickle=1)\n",
        "np_emb_test=np.load(\"bert_test.npy\",allow_pickle=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFpMlIADcyIE",
        "colab_type": "code",
        "outputId": "e4b3b8ae-34fe-4884-92dd-b14edd4b5c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "print(np_emb_train[0].shape)  \n",
        "print(np_emb_test.shape)  \n",
        "X_train = np_emb_train\n",
        "X_test = np_emb_test\n",
        "emb_list = []\n",
        "for i in X_train:\n",
        "  emb_list.append(torch.tensor(i[:31]))\n",
        "X_train = pad_sequence(emb_list, batch_first=True)\n",
        "#X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=500)\n",
        "emb_list = []\n",
        "for i in X_test:\n",
        "  emb_list.append(torch.tensor(i[:31]))\n",
        "X_test = pad_sequence(emb_list, batch_first=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18, 3072)\n",
            "(1869,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHtoZ9XqdWnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l=[]\n",
        "m=[]\n",
        "np_emb_train1=np.load(\"embed_copy.npy\",allow_pickle=1)\n",
        "np_emb_test1=np.load(\"embed_test_copy.npy\",allow_pickle=1)\n",
        "\n",
        "embeddings_polarity=np_emb_train1.tolist()\n",
        "for i in range(len(embeddings_polarity)):\n",
        "    l.append(embeddings_polarity[i][0])\n",
        "    if embeddings_polarity[i][1].lower()=='positive':\n",
        "        m.append(1)\n",
        "    elif embeddings_polarity[i][1].lower()=='negative':\n",
        "        m.append(2)\n",
        "    else:\n",
        "        m.append(0)\n",
        "l1=[]\n",
        "m1=[]\n",
        "embeddings_test=np_emb_test1.tolist()\n",
        "for i in range(len(embeddings_test)):\n",
        "    l1.append(embeddings_test[i][0])\n",
        "    if embeddings_test[i][1].lower()=='positive':\n",
        "        m1.append(1)\n",
        "    elif embeddings_test[i][1].lower()=='negative':\n",
        "        m1.append(2)\n",
        "    else:\n",
        "        m1.append(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vMUNqfIdg9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train=np.load(\"Ytrain.npy\")\n",
        "Y_test=np.load(\"ytest.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2VyLUnddisi",
        "colab_type": "code",
        "outputId": "9619f5a2-6d88-4b56-8925-b0cd04abe9b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def LSTM_model():\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(128,input_shape=(35,3072),return_sequences=1)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(SeqSelfAttention(attention_width=15,attention_activation='sigmoid'))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.add(GRU(20))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc',f1_m,precision_m, recall_m])\n",
        "    #print(model.summary())\n",
        "    filepath=\"lstm.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "    callbacks_list = [checkpoint]\n",
        "    model.fit(X_train.numpy(), Y_train, epochs=10, batch_size=256,callbacks=callbacks_list)\n",
        "    return model\n",
        "model=LSTM_model()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "15131/15131 [==============================] - 17s 1ms/step - loss: 1.0087 - acc: 0.4634 - f1_m: 0.1665 - precision_m: 0.5121 - recall_m: 0.1058\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.00873, saving model to lstm.hdf5\n",
            "Epoch 2/10\n",
            "15131/15131 [==============================] - 11s 753us/step - loss: 0.9085 - acc: 0.5447 - f1_m: 0.3757 - precision_m: 0.6627 - recall_m: 0.2671\n",
            "\n",
            "Epoch 00002: loss improved from 1.00873 to 0.90845, saving model to lstm.hdf5\n",
            "Epoch 3/10\n",
            "15131/15131 [==============================] - 11s 743us/step - loss: 0.8696 - acc: 0.5790 - f1_m: 0.4669 - precision_m: 0.6512 - recall_m: 0.3665\n",
            "\n",
            "Epoch 00003: loss improved from 0.90845 to 0.86962, saving model to lstm.hdf5\n",
            "Epoch 4/10\n",
            "15131/15131 [==============================] - 11s 742us/step - loss: 0.8299 - acc: 0.6062 - f1_m: 0.5379 - precision_m: 0.6568 - recall_m: 0.4564\n",
            "\n",
            "Epoch 00004: loss improved from 0.86962 to 0.82990, saving model to lstm.hdf5\n",
            "Epoch 5/10\n",
            "15131/15131 [==============================] - 11s 746us/step - loss: 0.7906 - acc: 0.6394 - f1_m: 0.6040 - precision_m: 0.6743 - recall_m: 0.5475\n",
            "\n",
            "Epoch 00005: loss improved from 0.82990 to 0.79059, saving model to lstm.hdf5\n",
            "Epoch 6/10\n",
            "15131/15131 [==============================] - 11s 735us/step - loss: 0.7420 - acc: 0.6705 - f1_m: 0.6488 - precision_m: 0.6951 - recall_m: 0.6085\n",
            "\n",
            "Epoch 00006: loss improved from 0.79059 to 0.74200, saving model to lstm.hdf5\n",
            "Epoch 7/10\n",
            "15131/15131 [==============================] - 11s 734us/step - loss: 0.6964 - acc: 0.7017 - f1_m: 0.6869 - precision_m: 0.7193 - recall_m: 0.6575\n",
            "\n",
            "Epoch 00007: loss improved from 0.74200 to 0.69639, saving model to lstm.hdf5\n",
            "Epoch 8/10\n",
            "15131/15131 [==============================] - 11s 738us/step - loss: 0.6411 - acc: 0.7333 - f1_m: 0.7247 - precision_m: 0.7483 - recall_m: 0.7027\n",
            "\n",
            "Epoch 00008: loss improved from 0.69639 to 0.64107, saving model to lstm.hdf5\n",
            "Epoch 9/10\n",
            "15131/15131 [==============================] - 11s 743us/step - loss: 0.5947 - acc: 0.7585 - f1_m: 0.7540 - precision_m: 0.7707 - recall_m: 0.7381\n",
            "\n",
            "Epoch 00009: loss improved from 0.64107 to 0.59470, saving model to lstm.hdf5\n",
            "Epoch 10/10\n",
            "15131/15131 [==============================] - 11s 735us/step - loss: 0.5525 - acc: 0.7800 - f1_m: 0.7762 - precision_m: 0.7903 - recall_m: 0.7627\n",
            "\n",
            "Epoch 00010: loss improved from 0.59470 to 0.55253, saving model to lstm.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x37hlYxkdk0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3bf809d-f8bf-4ce4-fe96-6b6c6a25599d"
      },
      "source": [
        "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, Y_test, verbose=0)\n",
        "accuracy, f1_score, precision,recall"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5141787053493971, 0.5078455995212205, 0.5159723916240017, 0.50026752293078)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOYsbRYFheqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "ade040cf-7950-408b-8579-44681b9d337d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_1 (Bidirection (None, 31, 256)           3277824   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 31, 256)           0         \n",
            "_________________________________________________________________\n",
            "seq_self_attention_1 (SeqSel (None, 31, 256)           16449     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 31, 3)             771       \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 20)                1440      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 3,296,547\n",
            "Trainable params: 3,296,547\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeC_yIEUubQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=model.predict_classes(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY2DkHpGpKnh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e418f87a-8e68-4156-8342-9ff17d57576d"
      },
      "source": [
        "y_dct = {'negative':0, \"neutral\":1,\"positive\":2}\n",
        "y_test_int = []\n",
        "for i in range(len(Y_test)):\n",
        "      y_test_int.append(list(Y_test[i]).index(1))\n",
        "from sklearn.metrics import classification_report as clf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "target_names=['negative','neutral','positive']\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_matrix(y_test_int, y_pred), columns=target_names, index=target_names)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "print(df_cm)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy: \",accuracy_score(y_test_int, y_pred))\n",
        "print(\"\\n\",\"Report:\")\n",
        "print(clf(y_test_int, y_pred, target_names=target_names))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted  negative  neutral  positive\n",
            "Actual                                \n",
            "negative        402      110        21\n",
            "neutral         322      334        98\n",
            "positive        133      224       225\n",
            "\n",
            "\n",
            "Accuracy:  0.5141787051899411\n",
            "\n",
            " Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.47      0.75      0.58       533\n",
            "     neutral       0.50      0.44      0.47       754\n",
            "    positive       0.65      0.39      0.49       582\n",
            "\n",
            "    accuracy                           0.51      1869\n",
            "   macro avg       0.54      0.53      0.51      1869\n",
            "weighted avg       0.54      0.51      0.51      1869\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGI3NzVpuUBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}